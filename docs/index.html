<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!--
  <script src="./resources/jsapi" type="text/javascript"></script>
  <script type="text/javascript" async>google.load("jquery", "1.3.2");</script>
 -->
    <style type="text/css">
        @font-face {
            font-family: 'Avenir Book';
            src: url("./fonts/Avenir_Book.ttf"); /* File to be stored at your site */
        }
    body {
    font-family: "Avenir Book", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:14px;
    margin-left: auto;
    margin-right: auto;
    width: 900px;
  }
  h1 {
    font-weight:300;
  }
  h2 {
    font-weight:300;
  }

  p {
    font-weight:300;
    line-height: 1.4;
  }

  code {
    font-size: 0.8rem;
    margin: 0 0.2rem;
    padding: 0.5rem 0.8rem;
    white-space: nowrap;
    background: #efefef;
    border: 1px solid #d3d3d3;
    color: #000000;
    border-radius: 3px;
  }

  pre > code {
    display: block;
    white-space: pre;
    line-height: 1.5;
    padding: 0;
    margin: 0;
  }

  pre.prettyprint > code {
    border: none;
  }


  .container {
        display: flex;
        align-items: center;
        justify-content: center
  }
  .image {
        flex-basis: 40%
  }
  .text {
        padding-left: 20px;
        padding-right: 20px;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 0px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;

  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>
	<title>Discriminative Adversarial Domain Adaptation</title>
</head>

<body>
<br>
<span style="font-size:36px">
    <div style="text-align: center;">
        Discriminative Adversarial Domain Adaptation
    </div>
</span>
<br>
<br>
<br>
<table align="center" width="700px">
    <tr>
        <td align="center" width="300px">
            <div style="text-align: center;">
                <span style="font-size:16px"><a href="https://huitangtang.github.io/">Hui Tang</a><sup>1</sup></span>
            </div>
        </td>
        
        <td align="center" width="300px">
            <div style="text-align: center;">
                <span style="font-size:16px">
                    <a href="http://kuijia.site/">Kui Jia</a>
<!--                    <sup><img class="round" style="width:20px" src="./resources/corresponding_fig.png">3</sup>-->
                    <sup>&#9993, 1</sup>
                </span>
            </div>
        </td>
    </tr>
</table>

<br>
	
<table align="center" width="700px">
    <tbody>
    <tr>
        <td align="center" width="300px">
            <center>
                <span style="font-size:16px">South China University of Technology<sup>1</sup></span>
            </center>
        </td>
    </tr>
    </tbody>
</table>


<table align="center" width="700px">
    <tbody>
    <tr>
        <td align="center" width="300px">
            <center>
                <span style="font-size:16px"><sup>&#9993</sup>Corresponding author</span>
            </center>
        </td>
    </tr>
    </tbody>
</table>

<table align="center" width="700px">
    <tbody>
    <tr>
        <td align="center" width="200px">
            <div style="text-align: center;">
                <span style="font-size:20px">
                    Code
                    <a href="https://github.com/huitangtang/DADA">[GitHub]</a>
                </span>
            </div>
        </td>

        <td align="center" width="200px">
            <div style="text-align: center;">
                <span style="font-size:20px">
                    Paper
                    <a href="https://ojs.aaai.org/index.php/AAAI/article/download/6054/5910">[CVF]</a>
                </span>
            </div>
        </td>

        <td align="center" width="200px">
            <center>
                <span style="font-size:20px">
                    Cite <a href="resources/cite.txt">[BibTeX]</a>
                </span>
            </center>
        </td>
    </tr>
    </tbody>
</table>
<br>
<hr>

<div style="text-align: center;">
    <h2>Teaser</h2>
</div>

<p style="text-align:justify; text-justify:inter-ideograph;">
<table>
    <tr>
        <td>
            <div style="text-align: center;">
                <img src="resources/DADA.png" width="900px">
            </div>
        </td>
    </tr>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		We propose a novel adversarial learning method termed Discriminative Adversarial Domain Adaptation (DADA). 
		Based on an integrated category and domain classifier, DADA has a novel adversarial objective that encourages a mutually inhibitory relation between category and domain predictions for any input instance. 
		Except for the traditional closed set domain adaptation, we also extend DADA for extremely challenging problem settings of partial and open set domain adaptation.
            </p>
        </td>
    </tr>
</table>


<br>
<hr>
<div style="text-align: center;">
    <h2>Abstract</h2>
</div>

<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		Given labeled instances on a source domain and unlabeled ones on a target domain, 
		unsupervised domain adaptation aims to learn a task classifier that can well classify target instances. 
		Recent advances rely on domain-adversarial training of deep networks to learn domain-invariant features. 
		However, due to an issue of mode collapse induced by the separate design of task and domain classifiers, 
		these methods are limited in aligning the joint distributions of feature and category across domains. 
		To overcome it, we propose a novel adversarial learning method termed Discriminative Adversarial Domain Adaptation (DADA). 
		Based on an integrated category and domain classifier, DADA has a novel adversarial objective that 
		encourages a mutually inhibitory relation between category and domain predictions for any input instance. 
		We show that under practical conditions, it defines a minimax game that can promote the joint distribution alignment. 
		Except for the traditional closed set domain adaptation, we also extend DADA for extremely challenging problem settings of partial and open set domain adaptation. 
		Experiments show the efficacy of our proposed methods and we achieve the new state of the art for all the three settings on benchmark datasets.
            </p>
        </td>
    </tr>
</table>

<br>
<hr>
<div style="text-align: center;">
    <h2>Background & Motivation</h2>
</div>

<table>
    <tr>
        <td>
            <div style="text-align: center;">
                <img src="resources/background.png" width="600px">
            </div>
        </td>
    </tr>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
                <br>
		Recent advances rely on domain-adversarial training of deep networks to learn domain-invariant features. 
		However, due to an issue of mode collapse induced by the separate design of task and domain classifiers, 
		these methods are limited in aligning the joint distributions of feature and category across domains. 
		To overcome it, we propose a novel adversarial learning method termed Discriminative Adversarial Domain Adaptation (DADA).
            </p>
        </td>
    </tr>
</table>

<br>
<hr>
<div style="text-align: center;">
    <h2>Highlights</h2>
</div>

<div style="text-align: center;">
    <h3>Discriminative Adversarial Learning</h3>
</div>
	
<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		To establish a direct interaction between category and domain predictions for any source instance, we propose a novel source discriminative adversarial loss that 
		is inspired by the principle of binary cross-entropy loss and tailored to the design of the integrated classifier.
		<br>
		<br>
		To achieve the joint distribution alignment, the explicit interplay between category and domain predictions for any target instance should also be created. 
		We propose a target discriminative adversarial loss based on the design of the integrated classifier. 
		It uses conditional category probabilities to weight the domain predictions.
            </p>
 	    <br>
	    <div style="text-align: center;">
                <img src="resources/gradient_change.png" width="500px">
            </div>
	    <p style="text-align: center;">
		Changes of category and domain predictions when minimizing and maximizing the proposed source discriminative adversarial loss in the two cases.
	    </p>
        </td>
    </tr>
</table>

<div style="text-align: center;">
    <h3>Extension for Partial Domain Adaptation</h3>
</div>
	
<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		Partial domain adaptation is a more realistic setting, where the target label space is subsumed by the source one. 
		We extend DADA for partial domain adaptation by using a reliable category-level weighting mechanism.
            </p>
        </td>
    </tr>
</table>

<div style="text-align: center;">
    <h3>Extension for Open Set Domain Adaptation</h3>
</div>
	
<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		Open set domain adaptation is a very challenging setting, where the source label space is subsumed by the target one. 
		We extend DADA for open set domain adaptation by training the classifier to classify all target instances as the unknown category with a small probability q, 
		which can achieve a balance between domain adaptation and outlier rejection.
            </p>
        </td>
    </tr>
</table>

<br>
<hr>
<div style="text-align: center;">
    <h2>Experiments</h2>
</div>

<div style="text-align: center;">
    <h3>Closed Set Domain Adaptation</h3>
</div>

<table>
    <tr>
        <td>
            <p>
                <b>
                    R1: Ablation Study
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		In the following table, we can observe that DANN improves over No Adaptation, its result is much worse than DANN-CA, 
		verifying the efficacy of the design of the integrated classifier. 
		DADA (w/o em + w/o td) improves over DANN-CA and 
		DADA (w/o em) improves over DADA (w/o em + w/o td), 
		showing the efficacy of our proposed discriminative adversarial learning. 
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab1.png" width="700px">
            </div>
        </td>
    </tr>


    <tr>
        <td>
            <br>
            <p>
                <b>
                    R2: Quantitative Comparison
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		The following figure shows that our proposed DADA gives the predicted probability on the true category of any target instance a better chance to approach 1, 
		meaning that target instances are more likely to be correctly classified by DADA, i.e., a better category-level domain alignment.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/average_probability.png" width="500px">
            </div>
	    <p style="text-align:center;">
		Average probability on the true category over all target instances by task classifiers of different methods.
	    </p>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R3: Feature Visualization
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		The following figure shows qualitative improvements of these methods at aligning features across data domains, 
		i.e., the distribution of target samples (red) changes from the scattered state of DANN to multiple category-wise clusters of DADA, 
		which are aligned with source samples (blue) of corresponding categories.
            </p>
        </td>
    </tr>
</table>

<table align="center" width="900px">
    <tbody>
    <br>
    <tr>
        <td>
            <div style="text-align: center;">
                <img src="resources/t_sne_resnet_new.png" width="200px">
            </div>
	    <p style="text-align:center;">
		(a) No Adaptation
	    </p>
        </td>
        <td>
            <div style="text-align: center;">
                <img src="resources/t_sne_dann_new.png" width="200px">
            </div>
	    <p style="text-align:center;">
		(b) DANN
	    </p>
        <td>
            <div style="text-align: center;">
                <img src="resources/t_sne_dann_ca.png" width="200px">
            </div>
	    <p style="text-align:center;">
		(c) DANN-CA
	    </p>
        <td>
            <div style="text-align: center;">
                <img src="resources/t_sne_fgil_new.png" width="200px">
            </div>
	    <p style="text-align:center;">
		(d) DADA
	    </p>
        </td>
    </tr>
    <tr>
	<td>
		The t-SNE visualization of feature alignment between the source (blue) and target (red) domains.
	</td>
    </tr>
    </tbody>
</table>

	
<div style="text-align: center;">
    <h3>Saliency Map Visualization</h3>
</div>

<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		In the following figure, it is observed that our methods learn better feature representations that capture more complete semantic patterns, e.g., first example.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/fig6.png" width="600px">
            </div>
	    <p style="text-align:center;">
		Visualizing the Grad-CAM saliency maps from the baseline FixMatch and our proposed GSF and PPF on 40- and 250-label settings. 
		Note that the number on top of each picture means the ground-truth (first column) or predicted labels (other columns).
	    </p>
        </td>
    </tr>
</table>
	
	
<div style="text-align: center;">
    <h3>Confidence Spectrum</h3>
</div>

<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
                In the following figure, we observe that the higher the confidence of a sample, the more inclined our method is to select it.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/fig7.png" width="500px">
            </div>
	    <p style="text-align:center;">
		Spectrum of confidence for samples selected by GSF and PPF. (128<sup>th</sup> epoch, CIFAR10@40).
	    </p>
        </td>
    </tr>
</table>


<div style="text-align: center;">
    <h3>Comparison with SOTA</h3>
</div>

<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		 Experiments on SSL benchmarks show that our methods based on FixMatch achieve significant improvements in accuracy, verifying their efficacy in filtering samples of moderate confidence.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab1.png" width="900px">
            </div>
	    <p style="text-align:center;">
		Error rates (%) for CIFAR-10, CIFAR-100, and SVHN.
	    </p>
        </td>
    </tr>
</table>
	
<br>
<hr>

<div style="text-align: center;">
    <h2>BibTeX</h2>
</div>
      <pre>
  	<code>
      @inproceedings{tang2020discriminative,
        title={Discriminative adversarial domain adaptation},
        author={Tang, Hui and Jia, Kui},
        booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
        volume={34},
        number={04},
        pages={5940--5947},
        year={2020}
      }
  	</code>
      </pre>
	
<br>
<hr>

<div style="text-align: center;">
    <h2>Acknowledgements</h2>
</div>
      <p>
	      Based on a template by <a href="https://kyanchen.github.io/OvarNet/">Keyan Chen</a>.
      </p>

<br>
<br>
<br>

</body>
</html>
