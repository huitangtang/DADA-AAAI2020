<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!--
  <script src="./resources/jsapi" type="text/javascript"></script>
  <script type="text/javascript" async>google.load("jquery", "1.3.2");</script>
 -->
    <style type="text/css">
        @font-face {
            font-family: 'Avenir Book';
            src: url("./fonts/Avenir_Book.ttf"); /* File to be stored at your site */
        }
    body {
    font-family: "Avenir Book", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:14px;
    margin-left: auto;
    margin-right: auto;
    width: 900px;
  }
  h1 {
    font-weight:300;
  }
  h2 {
    font-weight:300;
  }

  p {
    font-weight:300;
    line-height: 1.4;
  }

  code {
    font-size: 0.8rem;
    margin: 0 0.2rem;
    padding: 0.5rem 0.8rem;
    white-space: nowrap;
    background: #efefef;
    border: 1px solid #d3d3d3;
    color: #000000;
    border-radius: 3px;
  }

  pre > code {
    display: block;
    white-space: pre;
    line-height: 1.5;
    padding: 0;
    margin: 0;
  }

  pre.prettyprint > code {
    border: none;
  }


  .container {
        display: flex;
        align-items: center;
        justify-content: center
  }
  .image {
        flex-basis: 40%
  }
  .text {
        padding-left: 20px;
        padding-right: 20px;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 0px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;

  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>
	<title>Discriminative Adversarial Domain Adaptation</title>
</head>

<body>
<br>
<span style="font-size:36px">
    <div style="text-align: center;">
        Discriminative Adversarial Domain Adaptation
    </div>
</span>
<br>
<br>
<br>
<table align="center" width="700px">
    <tr>
        <td align="center" width="300px">
            <div style="text-align: center;">
                <span style="font-size:16px"><a href="https://huitangtang.github.io/">Hui Tang</a><sup>1</sup></span>
            </div>
        </td>
        
        <td align="center" width="300px">
            <div style="text-align: center;">
                <span style="font-size:16px">
                    <a href="http://kuijia.site/">Kui Jia</a>
<!--                    <sup><img class="round" style="width:20px" src="./resources/corresponding_fig.png">3</sup>-->
                    <sup>&#9993, 1</sup>
                </span>
            </div>
        </td>
    </tr>
</table>

<br>
	
<table align="center" width="700px">
    <tbody>
    <tr>
        <td align="center" width="300px">
            <center>
                <span style="font-size:16px">South China University of Technology<sup>1</sup></span>
            </center>
        </td>
    </tr>
    </tbody>
</table>


<table align="center" width="700px">
    <tbody>
    <tr>
        <td align="center" width="300px">
            <center>
                <span style="font-size:16px"><sup>&#9993</sup>Corresponding author</span>
            </center>
        </td>
    </tr>
    </tbody>
</table>

<table align="center" width="700px">
    <tbody>
    <tr>
        <td align="center" width="200px">
            <div style="text-align: center;">
                <span style="font-size:20px">
                    Code
                    <a href="https://github.com/huitangtang/DADA">[GitHub]</a>
                </span>
            </div>
        </td>

        <td align="center" width="200px">
            <div style="text-align: center;">
                <span style="font-size:20px">
                    Paper
                    <a href="https://ojs.aaai.org/index.php/AAAI/article/download/6054/5910">[CVF]</a>
                </span>
            </div>
        </td>

        <td align="center" width="200px">
            <center>
                <span style="font-size:20px">
                    Cite <a href="resources/cite.txt">[BibTeX]</a>
                </span>
            </center>
        </td>
    </tr>
    </tbody>
</table>
<br>
<hr>

<div style="text-align: center;">
    <h2>Teaser</h2>
</div>

<p style="text-align:justify; text-justify:inter-ideograph;">
<table>
    <tr>
        <td>
            <div style="text-align: center;">
                <img src="resources/DADA.png" width="900px">
            </div>
        </td>
    </tr>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		We propose a novel adversarial learning method termed Discriminative Adversarial Domain Adaptation (DADA). 
		Based on an integrated category and domain classifier, DADA has a novel adversarial objective that encourages a mutually inhibitory relation between category and domain predictions for any input instance. 
		Except for the traditional closed set domain adaptation, we also extend DADA for extremely challenging problem settings of partial and open set domain adaptation.
            </p>
        </td>
    </tr>
</table>


<br>
<hr>
<div style="text-align: center;">
    <h2>Abstract</h2>
</div>

<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		Given labeled instances on a source domain and unlabeled ones on a target domain, 
		unsupervised domain adaptation aims to learn a task classifier that can well classify target instances. 
		Recent advances rely on domain-adversarial training of deep networks to learn domain-invariant features. 
		However, due to an issue of mode collapse induced by the separate design of task and domain classifiers, 
		these methods are limited in aligning the joint distributions of feature and category across domains. 
		To overcome it, we propose a novel adversarial learning method termed Discriminative Adversarial Domain Adaptation (DADA). 
		Based on an integrated category and domain classifier, DADA has a novel adversarial objective that 
		encourages a mutually inhibitory relation between category and domain predictions for any input instance. 
		We show that under practical conditions, it defines a minimax game that can promote the joint distribution alignment. 
		Except for the traditional closed set domain adaptation, we also extend DADA for extremely challenging problem settings of partial and open set domain adaptation. 
		Experiments show the efficacy of our proposed methods and we achieve the new state of the art for all the three settings on benchmark datasets.
            </p>
        </td>
    </tr>
</table>

<br>
<hr>
<div style="text-align: center;">
    <h2>Background & Motivation</h2>
</div>

<table>
    <tr>
        <td>
            <div style="text-align: center;">
                <img src="resources/background.png" width="600px">
            </div>
        </td>
    </tr>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
                <br>
		Recent advances rely on domain-adversarial training of deep networks to learn domain-invariant features. 
		However, due to an issue of mode collapse induced by the separate design of task and domain classifiers, 
		these methods are limited in aligning the joint distributions of feature and category across domains. 
		To overcome it, we propose a novel adversarial learning method termed Discriminative Adversarial Domain Adaptation (DADA).
            </p>
        </td>
    </tr>
</table>

<br>
<hr>
<div style="text-align: center;">
    <h2>Highlights</h2>
</div>

<div style="text-align: center;">
    <h3>Discriminative Adversarial Learning</h3>
</div>
	
<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		To establish a direct interaction between category and domain predictions for any source instance, we propose a novel source discriminative adversarial loss that 
		is inspired by the principle of binary cross-entropy loss and tailored to the design of the integrated classifier.
	    </p>
 	    <br>
	    <div style="text-align: center;">
                <img src="resources/gradient_change.png" width="500px">
            </div>
	    <p style="text-align: center;">
		Changes of category and domain predictions when minimizing and maximizing the proposed source discriminative adversarial loss in the two cases.
	    </p>
	    <br>
	    <p>
		To achieve the joint distribution alignment, the explicit interplay between category and domain predictions for any target instance should also be created. 
		We propose a target discriminative adversarial loss based on the design of the integrated classifier. 
		It uses conditional category probabilities to weight the domain predictions.
            </p>
        </td>
    </tr>
</table>

<div style="text-align: center;">
    <h3>Extension for Partial Domain Adaptation</h3>
</div>
	
<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		Partial domain adaptation is a more realistic setting, where the target label space is subsumed by the source one. 
		We extend DADA for partial domain adaptation by using a reliable category-level weighting mechanism.
            </p>
        </td>
    </tr>
</table>

<div style="text-align: center;">
    <h3>Extension for Open Set Domain Adaptation</h3>
</div>
	
<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		Open set domain adaptation is a very challenging setting, where the source label space is subsumed by the target one. 
		We extend DADA for open set domain adaptation by training the classifier to classify all target instances as the unknown category with a small probability q, 
		which can achieve a balance between domain adaptation and outlier rejection.
            </p>
        </td>
    </tr>
</table>

<div style="text-align: center;">
    <h3>Generalization Error Analysis</h3>
</div>
	
<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		Our proposed DADA can formally better bound the expected target error than existing domain adaptation methods, 
		which aim to measure and minimize the F-distance or the D-distance. 
		The F<sub>H</sub>-distance can be upper bounded by the optimal solution of DADA.
            </p>
 	    <br>
	    <div style="text-align: center;">
                <img src="resources/theorem1.png" width="500px">
            </div>
        </td>
    </tr>
</table>


<br>
<hr>
<div style="text-align: center;">
    <h2>Experiments</h2>
</div>

<div style="text-align: center;">
    <h3>Closed Set Domain Adaptation</h3>
</div>

<table>
    <tr>
        <td>
            <p>
                <b>
                    R1: Ablation Study
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		In the following table, we can observe that DANN improves over No Adaptation, its result is much worse than DANN-CA, 
		verifying the efficacy of the design of the integrated classifier. 
		DADA (w/o em + w/o td) improves over DANN-CA and 
		DADA (w/o em) improves over DADA (w/o em + w/o td), 
		showing the efficacy of our proposed discriminative adversarial learning. 
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab1.png" width="700px">
            </div>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R2: Quantitative Comparison
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		The following figure shows that our proposed DADA gives the predicted probability on the true category of any target instance a better chance to approach 1, 
		meaning that target instances are more likely to be correctly classified by DADA, i.e., a better category-level domain alignment.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/average_probability.png" width="500px">
            </div>
	    <p style="text-align:center;">
		Average probability on the true category over all target instances by task classifiers of different methods.
	    </p>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R3: Feature Visualization
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		The following figure shows qualitative improvements of these methods at aligning features across data domains, 
		i.e., the distribution of target samples (red) changes from the scattered state of DANN to multiple category-wise clusters of DADA, 
		which are aligned with source samples (blue) of corresponding categories.
            </p>
        </td>
    </tr>
</table>

<table align="center" width="900px">
    <tbody>
    <br>
    <tr>
        <td>
            <div style="text-align: center;">
                <img src="resources/t_sne_resnet_new.png" width="200px">
            </div>
	    <p style="text-align:center;">
		(a) No Adaptation
	    </p>
        </td>
        <td>
            <div style="text-align: center;">
                <img src="resources/t_sne_dann_new.png" width="200px">
            </div>
	    <p style="text-align:center;">
		(b) DANN
	    </p>
        <td>
            <div style="text-align: center;">
                <img src="resources/t_sne_dann_ca.png" width="200px">
            </div>
	    <p style="text-align:center;">
		(c) DANN-CA
	    </p>
        <td>
            <div style="text-align: center;">
                <img src="resources/t_sne_fgil_new.png" width="200px">
            </div>
	    <p style="text-align:center;">
		(d) DADA
	    </p>
        </td>
    </tr>
    </tbody>
</table>

<table>
    <tr>
	<td>
	    <p style="text-align:center;">
		The t-SNE visualization of feature alignment between the source (blue) and target (red) domains.
	    </p>
	</td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R4:  An In-Depth Analysis of Our Training Scheme
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		"Rate of Source Instances Failing to Satisfy Condition" declines to a very low value in an oscillatory manner, 
		showing the efficacy of this training scheme in keeping the condition satisfied.
		<br>
		<br>
		All valleys of "Test Error of Target Data" are derived from the adversarial training of DADA, 
		showing the excellent efficacy of our proposed DADA in aligning the source and target domains. 
		At epochs of adversarial training, the lower "Rate of Source Instances Failing to Satisfy Condition" is, 
		the more improvement of performance is obtained, showing the necessity of satisfying the condition. 
		<br>
		<br>
		The good performances of DADA on the two adaptation settings of MNIST→USPS and USPS→MNIST, which are very close to the perfect performance of 100%, 
		confirm the efficacy of our proposed DADA in aligning the joint distributions of feature and category across the two domains. 
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/m2u_5lines_32alter.png" width="700px">
            </div>
	    <p style="text-align:center;">
		(a) MNIST→USPS (N<sub>alter</sub> = 32)
	    </p>
            <div style="text-align: center;">
                <img src="resources/u2m_5lines_32alter.png" width="700px">
            </div>
	    <p style="text-align:center;">
		(b) USPS→MNIST (N<sub>alter</sub> = 32)
	    </p>
        </td>
    </tr>
	
    <tr>
        <td>
            <br>
            <p>
                <b>
                    R5: Comparison with SOTA
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		Our proposed DADA outperforms existing methods, testifying the efficacy of DADA in aligning the joint distributions of feature and category across domains. 
		Our proposed DADA consistently achieves a good result on different adaptation settings, showing its excellent robustness. 
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab2.png" width="700px">
            </div>
	    <p style="text-align:center;">
		Results for closed set domain adaptation on Office-31 based on ResNet-50.
	    </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab3.png" width="900px">
            </div>
	    <p style="text-align:center;">
		Results for closed set domain adaptation on Syn2Real-C based on ResNet-101.
	    </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab7.png" width="700px">
            </div>
	    <p style="text-align:center;">
		Results for closed set domain adaptation on Digits based on LeNet.
	    </p>
        </td>
    </tr>
</table>

	
<div style="text-align: center;">
    <h3>Partial Domain Adaptation</h3>
</div>

<table>
    <tr>
        <td>
            <p>
                <b>
                    R1: Effects of the Number of Target Categories
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		The following figure shows that our proposed DADA-P performs much better than DANN in all settings. 
		It is noteworthy that the relative performance improvement becomes larger 
		when the number of target categories decreases, 
		testifying the superiority of our methods in reducing the influence of negative transfer. 
		Thus, given a source domain, our methods can perform much better 
		when applied to the target domain with unknown number of categories.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/vary_tarC_new.png" width="500px">
            </div>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R2: Effects of the Number of Outlier Source Categories
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		The following figure shows that our proposed DADA-P significantly outperforms DANN in all settings. 
		Particularly, the relative performance improvement is larger when the number of source categories is larger, 
		demonstrating that our methods are more robust to the number of outlier source categories. 
		Thus, for a given target task, our methods can have a much better performance when utilizing different source tasks.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/vary_srcC_new.png" width="500px">
            </div>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R3: Comparison with SOTA
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		Our proposed DADA-P substantially outperforms all comparative methods, 
		showing the effectiveness of DADA-P on reducing the negative influence of source outliers 
		while promoting the joint distribution alignment in the shared label space.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab5.png" width="400px">
            </div>
	    <p style="text-align:center;">
		Results for partial domain adaptation on Syn2Real-C based on ResNet-50.
	    </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab8.png" width="700px">
            </div>
	    <p style="text-align:center;">
		Results for partial domain adaptation on Office-31 based on ResNet-50.
	    </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab9.png" width="700px">
            </div>
	    <p style="text-align:center;">
		Results for partial domain adaptation on Office-31 based on AlexNet.
	    </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab10.png" width="900px">
            </div>
	    <p style="text-align:center;">
		Results for partial domain adaptation on Office-Home based on ResNet-50.
	    </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab11.png" width="400px">
            </div>
	    <p style="text-align:center;">
		Results for partial domain adaptation on ImageNet-Caltech based on ResNet-50.
	    </p>
        </td>
    </tr>
</table>
	
	
<div style="text-align: center;">
    <h3>Open Set Domain Adaptation</h3>
</div>

<table>
    <tr>
        <td>
            <p>
                <b>
                    R1: Effects of the Small Probability
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		As the small probability q increases, accuracies of OS and OS* decrease and the accuracy of Unknown increases, 
		which means that the target instances are more likely classified as the unknown category. 
		When q = 0, the objective of the feature extractor is to align the whole source domain and the whole target domain, 
		resulting in the misclassification of all unknown target instances as the known categories. 
		To make a trade-off, we empirically set q = 0.1 for all open set adaptation settings.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/open_set_vary_t_new.png" width="500px">
            </div>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R2: Comparison with SOTA
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		Our proposed DADA-O outperforms all comparative methods in both evaluation metrics of Known and Mean, 
		showing the efficacy of DADA-O in both aligning joint distributions of the known instances and identifying the unknown target instances.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab4.png" width="900px">
            </div>
	    <p style="text-align:center;">
		Results for open set domain adaptation on Syn2Real-O based on ResNet-152.
	    </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab12.png" width="900px">
            </div>
	    <p style="text-align:center;">
		Results for open set domain adaptation on Office-31 based on AlexNet.
	    </p>
        </td>
    </tr>
</table>

	
<br>
<hr>

<div style="text-align: center;">
    <h2>BibTeX</h2>
</div>
      <pre>
  	<code>
      @inproceedings{tang2020discriminative,
        title={Discriminative adversarial domain adaptation},
        author={Tang, Hui and Jia, Kui},
        booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
        volume={34},
        number={04},
        pages={5940--5947},
        year={2020}
      }
  	</code>
      </pre>
	
<br>
<hr>

<div style="text-align: center;">
    <h2>Acknowledgements</h2>
</div>
      <p>
	      Based on a template by <a href="https://kyanchen.github.io/OvarNet/">Keyan Chen</a>.
      </p>

<br>
<br>
<br>

</body>
</html>
